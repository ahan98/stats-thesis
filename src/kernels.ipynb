{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bechmarking Custom Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA, Random\n",
    "using Test, BenchmarkTools\n",
    "CUDA.allowscalar(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partition (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"perm_test.jl\")\n",
    "include(\"partition.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 1.89% (153.625 MiB/7.936 GiB)\n",
      "No memory pool is in use."
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set_thread_block (generic function with 2 methods)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function set_thread_block(len, nthreads=256)\n",
    "    nblocks = ceil(Int, len / nthreads)\n",
    "    return nthreads, nblocks\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1 2 … 11 12; 1 2 … 11 13; … ; 8 10 … 19 20; 9 10 … 19 20], [20 19 … 14 13; 20 19 … 14 12; … ; 9 7 … 2 1; 8 7 … 2 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2^15                    # num. samples\n",
    "T, B = set_thread_block(N)\n",
    "nx, ny = 12, 8              # sample sizes for each group\n",
    "x, y = CUDA.rand(Float64, N, nx), CUDA.rand(Float64, N, ny)\n",
    "px, py = partition(nx, ny)\n",
    "px, py = CuArray(px), CuArray(py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean & Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(out, mean(x, dims = 2))\n",
       "   Evaluated: isapprox([0.35853716622161697, 0.3091693259738932, 0.689691935252548, 0.47212022013793603, 0.41096342341292136, 0.6515839175455919, 0.42196401231345776, 0.5022668870015077, 0.600749682796924, 0.5165848241247455  …  0.5753852698107481, 0.4772818330704583, 0.5316436073848941, 0.6056038081204794, 0.4095856354200143, 0.39356171787676003, 0.6022315024473835, 0.3286615267603409, 0.4807587984501902, 0.5358573367271325], [0.35853716622161697; 0.3091693259738932; … ; 0.4807587984501902; 0.5358573367271325;;])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mean!(x, ncol, out)\n",
    "    \"\"\"out = sum(x, dims=2)\"\"\"\n",
    "    row_idx = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    for i = 1:ncol\n",
    "        @inbounds out[row_idx] += x[row_idx, i]\n",
    "    end\n",
    "    @inbounds out[row_idx] /= ncol\n",
    "    return\n",
    "end\n",
    "\n",
    "out = CUDA.zeros(Float64, N)\n",
    "@cuda threads=T blocks=B mean!(x, size(x)[2], out)\n",
    "@test isapprox(out, mean(x, dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(out, sum(x .^ 2, dims = 2))\n",
       "   Evaluated: isapprox([2.4598905191141793, 2.1331097392573004, 6.457076804953674, 4.271737362977878, 2.8739343099876766, 5.96193317235129, 3.0131836235342, 4.11507195311366, 5.557911735957049, 4.77081110941095  …  4.719813463028387, 3.2924660221333895, 4.544027700111192, 5.052011870121489, 2.697714680372116, 2.7336969619443443, 5.288301260517309, 1.991310374632858, 3.5751915973356128, 4.667735857992992], [2.459890519114179; 2.1331097392573004; … ; 3.5751915973356128; 4.667735857992992;;])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sumsq!(x, ncol, out)\n",
    "    \"\"\"out = sum(x, dims=2)\"\"\"\n",
    "    row_idx = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    for i = 1:ncol\n",
    "        @inbounds out[row_idx] += x[row_idx, i]^2\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "out = CUDA.zeros(Float64, N)\n",
    "@cuda threads=T blocks=B sumsq!(x, size(x)[2], out)\n",
    "@test isapprox(out, sum(x.^2, dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_gpu (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function _var!(n, ss, means, out)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds out[i] = (ss[i] - (n * means[i]^2)) / (n-1)\n",
    "    return\n",
    "end\n",
    "\n",
    "function var_gpu(x)\n",
    "    nrow, ncol = size(x)\n",
    "    T, B = set_thread_block(nrow)\n",
    "    ss = CUDA.zeros(Float64, size(x)[1])\n",
    "    @cuda threads=T blocks=B sumsq!(x, ncol, ss)\n",
    "\n",
    "    means = CUDA.zeros(Float64, nrow)\n",
    "    @cuda threads=T blocks=B mean!(x, ncol, means)\n",
    "\n",
    "    vars = CUDA.zeros(Float64, nrow)\n",
    "    @cuda threads=T blocks=B _var!(ncol, ss, means, vars)\n",
    "    return vars, means\n",
    "end\n",
    "\n",
    "z = CUDA.rand(Float64, 300, 20)  # works with arbitrary matrix (i.e., dimensions don't have to be multiple of 256)\n",
    "@test isapprox(var_gpu(z)[1], var(z, dims=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t Test Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_arr_gpu! (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mul_gpu!(x, val)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] *= val\n",
    "    return\n",
    "end\n",
    "\n",
    "function mul_arr_gpu!(x, y)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] *= y[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "function div_gpu!(x, val)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] /= val\n",
    "    return\n",
    "end\n",
    "\n",
    "function div_arr_gpu!(x, y)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] /= y[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "function sqrt_gpu!(x)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] = sqrt(x[i])\n",
    "    return\n",
    "end\n",
    "\n",
    "function add_gpu!(a, b, c)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds c[i] = a[i] + b[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "function subtract_gpu!(a, b, c)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds c[i] = a[i] - b[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "function copy_arr_gpu!(dest, source)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds dest[i] = source[i]\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t_gpu (generic function with 2 methods)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function t_gpu(x, y, pooled)\n",
    "    varx, meanx = var_gpu(x)\n",
    "    vary, meany = var_gpu(y)\n",
    "    nx, ny = size(x, 2), size(y, 2)\n",
    "    T, B = set_thread_block(size(x,1))\n",
    "    \n",
    "    if pooled\n",
    "        @cuda threads=T blocks=B mul_gpu!(varx, nx-1)\n",
    "        @cuda threads=T blocks=B mul_gpu!(vary, ny-1)\n",
    "        @cuda threads=T blocks=B add_gpu!(varx, vary, varx)   # varx = (nx-1)*varx + (ny-1)*vary\n",
    "        @cuda threads=T blocks=B div_gpu!(varx, nx+ny-2)      # varx /= nx+ny-2\n",
    "        #@cuda threads=256 blocks=4 copy_arr_gpu!(vary, varx)\n",
    "        copyto!(vary, varx)\n",
    "    end\n",
    "        \n",
    "    @cuda threads=T blocks=B div_gpu!(varx, nx)\n",
    "    @cuda threads=T blocks=B div_gpu!(vary, ny)\n",
    "    \n",
    "    denom = CUDA.zeros(Float64, size(x)[1])\n",
    "    @cuda threads=T blocks=B add_gpu!(varx, vary, denom)\n",
    "    @cuda threads=T blocks=B sqrt_gpu!(denom)\n",
    "    \n",
    "    t = CUDA.zeros(Float64, size(x)[1])\n",
    "    @cuda threads=T blocks=B subtract_gpu!(meanx, meany, t)\n",
    "    @cuda threads=T blocks=B div_arr_gpu!(t, denom)\n",
    "    return t\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(t_gpu(x[1:10, :], y[1:10, :], pooled), ttest_ind(x[1:10, :], y[1:10, :], pooled))\n",
       "   Evaluated: isapprox([-0.6084672400601868, -1.3656430152327157, 1.3233596834837367, -0.808655969482445, -0.919506217068944, 0.48850609480561896, 0.22310357447735862, 0.35679933928850255, 1.2260926596041675, 0.8993202025114901], [-0.6084672400601863; -1.3656430152327155; … ; 1.2260926596041692; 0.8993202025114894;;])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled = false\n",
    "start, stop = 1, 10\n",
    "a, b = x[start:stop, :], y[start:stop, :]\n",
    "@test isapprox(\n",
    "    t_gpu(a, b, pooled),\n",
    "    ttest_ind(a, b, pooled)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t Test Statistic: `@cuda` vs. `@.` vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  248.894 μs (428 allocations: 22.92 KiB)\n",
      "  706.026 μs (340 allocations: 19.33 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32768×1 CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}:\n",
       " -0.23448901664480554\n",
       "  0.05901404020274746\n",
       "  0.38193147235097874\n",
       " -1.1025761619685284\n",
       " -0.37842271181044496\n",
       " -0.5640191022990872\n",
       "  0.9204858513562348\n",
       " -0.5540337831883215\n",
       " -2.022682039847497\n",
       " -0.30371442721737457\n",
       "  1.5446552677841405\n",
       " -0.3557875158409345\n",
       " -1.23487851962008\n",
       "  ⋮\n",
       " -0.41275974205144184\n",
       " -1.993862076306121\n",
       " -0.7057823538090785\n",
       " -0.6766744521720237\n",
       "  2.142521777498816\n",
       " -1.7249230335734638\n",
       "  1.0848105576581777\n",
       "  1.2222689568584562\n",
       " -0.5442251380071487\n",
       "  0.11810933367877134\n",
       "  0.5399342464957391\n",
       "  1.2943106132842193"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime t_gpu($x, $y, pooled=$pooled)\n",
    "@btime ttest_ind($x, $y, $pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.525 μs (0 allocations: 0 bytes)\n",
      "  6.128 μs (24 allocations: 1.28 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: all(a .== b)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CUDA.rand(N)\n",
    "b = CUDA.zeros(N)\n",
    "\n",
    "@btime copyto!($b, $a)\n",
    "@btime @cuda threads=T blocks=B copy_arr_gpu!(b, a)\n",
    "@test all(a .== b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing `CuArray`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.660 μs (4 allocations: 128 bytes)\n",
      "  12.167 μs (22 allocations: 1.11 KiB)\n",
      "  26.057 μs (7 allocations: 78.31 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element CuArray{Float64, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime CuArray{Float64, 1}(undef, 10_000)\n",
    "@btime CUDA.zeros(Float64, 10_000)\n",
    "@btime CuArray(zeros(10_000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.7.1",
   "language": "julia",
   "name": "julia-(8-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
