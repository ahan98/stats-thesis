{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bechmarking Custom Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA, Random\n",
    "using Test, BenchmarkTools\n",
    "CUDA.allowscalar(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partition (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"perm_test.jl\")\n",
    "include(\"partition.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 1.10% (89.500 MiB/7.936 GiB)\n",
      "No memory pool is in use."
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set_thread_block (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function set_thread_block(len, nthreads=256)\n",
    "    nblocks = ceil(Int, len / nthreads)\n",
    "    return nthreads, nblocks\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1 2 … 11 12; 1 2 … 11 13; … ; 8 10 … 19 20; 9 10 … 19 20], [20 19 … 14 13; 20 19 … 14 12; … ; 9 7 … 2 1; 8 7 … 2 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2^15                    # num. samples\n",
    "T, B = set_thread_block(N)\n",
    "nx, ny = 12, 8              # sample sizes for each group\n",
    "x, y = CUDA.rand(Float64, N, nx), CUDA.rand(Float64, N, ny)\n",
    "px, py = partition(nx, ny)\n",
    "px, py = CuArray(px), CuArray(py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean & Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(out, mean(x, dims = 2))\n",
       "   Evaluated: isapprox([0.4672852542253805, 0.551041753452703, 0.5985412991637825, 0.4226288275419107, 0.5317097044519004, 0.4342811713741532, 0.6866815818336852, 0.4392179624362464, 0.34722126058832464, 0.5840441773507449  …  0.3457239181502297, 0.5337717200348154, 0.38929762460815415, 0.5436974949083385, 0.4109756444706507, 0.3974622649104835, 0.6568111480839699, 0.5282659231047768, 0.5078012153777888, 0.4573249937726236], [0.4672852542253805; 0.551041753452703; … ; 0.5078012153777888; 0.4573249937726236;;])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mean!(x, ncol, out)\n",
    "    \"\"\"out = sum(x, dims=2)\"\"\"\n",
    "    row_idx = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    for i = 1:ncol\n",
    "        @inbounds out[row_idx] += x[row_idx, i]\n",
    "    end\n",
    "    @inbounds out[row_idx] /= ncol\n",
    "    return\n",
    "end\n",
    "\n",
    "out = CUDA.zeros(Float64, N)\n",
    "@cuda threads=T blocks=B mean!(x, size(x)[2], out)\n",
    "@test isapprox(out, mean(x, dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(out, sum(x .^ 2, dims = 2))\n",
       "   Evaluated: isapprox([3.693223999791831, 4.978098740272386, 5.285090633465086, 3.440420883931469, 4.089495444177012, 3.2780957378038167, 6.466351815623792, 2.881706696619888, 2.5407194751662336, 4.561802191965835  …  2.331504998496828, 4.152356548441717, 2.8892253011640694, 4.535481878976794, 2.8936879257120185, 2.931741671330754, 5.814172274833773, 4.1577661411085405, 3.9571249475068866, 3.6563412779424125], [3.6932239997918304; 4.978098740272386; … ; 3.9571249475068866; 3.6563412779424125;;])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sumsq!(x, ncol, out)\n",
    "    \"\"\"out = sum(x, dims=2)\"\"\"\n",
    "    row_idx = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    for i = 1:ncol\n",
    "        @inbounds out[row_idx] += x[row_idx, i]^2\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "out = CUDA.zeros(Float64, N)\n",
    "@cuda threads=T blocks=B sumsq!(x, size(x)[2], out)\n",
    "@test isapprox(out, sum(x.^2, dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox((var_gpu(z))[1], var(z, dims = 2))\n",
       "   Evaluated: isapprox([0.08429197235765579, 0.0744182583300651, 0.08567219715305538, 0.05947543373856663, 0.11287290751278621, 0.06848336639028041, 0.0880558708589525, 0.09886973090462484, 0.09423904555083636, 0.0861626352703772  …  0.06380125280728965, 0.06363696274728829, 0.07324037579453938, 0.06096120654117144, 0.06636931532131247, 0.10343917966082875, 0.09541847889025085, 0.0774501037223696, 0.09305758436870598, 0.06853871531191043], [0.0842919723576558; 0.07441825833006517; … ; 0.09305758436870609; 0.06853871531191041;;])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function _var!(n, ss, means, out)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds out[i] = (ss[i] - (n * means[i]^2)) / (n-1)\n",
    "    return\n",
    "end\n",
    "\n",
    "function var_gpu(x)\n",
    "    nrow, ncol = size(x)\n",
    "    T, B = set_thread_block(nrow)\n",
    "    ss = CUDA.zeros(Float64, size(x)[1])\n",
    "    @cuda threads=T blocks=B sumsq!(x, ncol, ss)\n",
    "\n",
    "    means = CUDA.zeros(Float64, nrow)\n",
    "    @cuda threads=T blocks=B mean!(x, ncol, means)\n",
    "\n",
    "    vars = CUDA.zeros(Float64, nrow)\n",
    "    @cuda threads=T blocks=B _var!(ncol, ss, means, vars)\n",
    "    return vars, means\n",
    "end\n",
    "\n",
    "z = CUDA.rand(Float64, 300, 20)  # works with arbitrary matrix size\n",
    "@test isapprox(var_gpu(z)[1], var(z, dims=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t Test Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_arr_gpu! (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mul_gpu!(x, val)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] *= val\n",
    "    return\n",
    "end\n",
    "\n",
    "function mul_arr_gpu!(x, y)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] *= y[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "function div_gpu!(x, val)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] /= val\n",
    "    return\n",
    "end\n",
    "\n",
    "function div_arr_gpu!(x, y)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] /= y[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "function add_gpu!(x, val)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] += val\n",
    "    return\n",
    "end\n",
    "\n",
    "function add_arr_gpu!(x, y)\n",
    "    \"\"\" out = x ./ y \"\"\"\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] += y[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "function sub_gpu!(a, b, c)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] -= val\n",
    "    return\n",
    "end\n",
    "\n",
    "function sub_arr_gpu!(x, y)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] -= y[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "function sqrt_gpu!(x)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds x[i] = sqrt(x[i])\n",
    "    return\n",
    "end\n",
    "\n",
    "function copy_arr_gpu!(dest, source)\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    @inbounds dest[i] = source[i]\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[12]:30\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: isapprox(t_gpu(a, b, pooled), ttest_ind(a, b, pooled))\n",
      "  MethodError: no method matching div_arr_gpu!(::CuDeviceVector{Float64, 1}, ::CuDeviceVector{Float64, 1})\n",
      "  \u001b[0mClosest candidates are:\n",
      "  \u001b[0m  div_arr_gpu!(::Any, ::Any) at In[11]:22\n",
      "  \u001b[0m  div_arr_gpu!(::Any, ::Any, \u001b[91m::Any\u001b[39m) at In[9]:22\n",
      "  Stacktrace:\n",
      "    [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/GPUCompiler/HeCT6/src/\u001b[39m\u001b[90m\u001b[4mcache.jl:0\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [2] \u001b[0m\u001b[1mspecialization_id\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mjob\u001b[39m::\u001b[0mGPUCompiler.CompilerJob\u001b[90m{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams, GPUCompiler.FunctionSpec{typeof(div_arr_gpu!), Tuple{CuDeviceVector{Float64, 1}, CuDeviceVector{Float64, 1}}}}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[35mGPUCompiler\u001b[39m \u001b[90m~/.julia/packages/GPUCompiler/HeCT6/src/\u001b[39m\u001b[90m\u001b[4mcache.jl:12\u001b[24m\u001b[39m\n",
      "    [3] \u001b[0m\u001b[1mcached_compilation\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mcache\u001b[39m::\u001b[0mDict\u001b[90m{UInt64, Any}\u001b[39m, \u001b[90mjob\u001b[39m::\u001b[0mGPUCompiler.CompilerJob, \u001b[90mcompiler\u001b[39m::\u001b[0mtypeof(CUDA.cufunction_compile), \u001b[90mlinker\u001b[39m::\u001b[0mtypeof(CUDA.cufunction_link)\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[35mGPUCompiler\u001b[39m \u001b[90m~/.julia/packages/GPUCompiler/HeCT6/src/\u001b[39m\u001b[90m\u001b[4mcache.jl:71\u001b[24m\u001b[39m\n",
      "    [4] \u001b[0m\u001b[1mcufunction\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(div_arr_gpu!), \u001b[90mtt\u001b[39m::\u001b[0mType\u001b[90m{Tuple{CuDeviceVector{Float64, 1}, CuDeviceVector{Float64, 1}}}\u001b[39m; \u001b[90mname\u001b[39m::\u001b[0mNothing, \u001b[90mkwargs\u001b[39m::\u001b[0mBase.Pairs\u001b[90m{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[36mCUDA\u001b[39m \u001b[90m~/.julia/packages/CUDA/sCev8/src/compiler/\u001b[39m\u001b[90m\u001b[4mexecution.jl:297\u001b[24m\u001b[39m\n",
      "    [5] \u001b[0m\u001b[1mcufunction\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(div_arr_gpu!), \u001b[90mtt\u001b[39m::\u001b[0mType\u001b[90m{Tuple{CuDeviceVector{Float64, 1}, CuDeviceVector{Float64, 1}}}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[36mCUDA\u001b[39m \u001b[90m~/.julia/packages/CUDA/sCev8/src/compiler/\u001b[39m\u001b[90m\u001b[4mexecution.jl:291\u001b[24m\u001b[39m\n",
      "    [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/CUDA/sCev8/src/compiler/\u001b[39m\u001b[90m\u001b[4mexecution.jl:102\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [7] \u001b[0m\u001b[1mt_gpu\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mCuArray\u001b[90m{Float64, 2, CUDA.Mem.DeviceBuffer}\u001b[39m, \u001b[90my\u001b[39m::\u001b[0mCuArray\u001b[90m{Float64, 2, CUDA.Mem.DeviceBuffer}\u001b[39m, \u001b[90mpooled\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[32mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[12]:23\u001b[24m\u001b[39m\n",
      "    [8] top-level scope\n",
      "  \u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.1/share/julia/stdlib/v1.7/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:445\u001b[24m\u001b[39m\n",
      "    [9] \u001b[0m\u001b[1meval\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:373\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [10] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:1196\u001b[24m\u001b[39m\n",
      "   [11] \u001b[0m\u001b[1msoftscope_include_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[33mSoftGlobalScope\u001b[39m \u001b[90m~/.julia/packages/SoftGlobalScope/u4UzH/src/\u001b[39m\u001b[90m\u001b[4mSoftGlobalScope.jl:65\u001b[24m\u001b[39m\n",
      "   [12] \u001b[0m\u001b[1mexecute_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket, \u001b[90mmsg\u001b[39m::\u001b[0mIJulia.Msg\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[35mIJulia\u001b[39m \u001b[90m~/.julia/packages/IJulia/e8kqU/src/\u001b[39m\u001b[90m\u001b[4mexecute_request.jl:67\u001b[24m\u001b[39m\n",
      "   [13] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:716\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [14] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:714\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [15] \u001b[0m\u001b[1meventloop\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[35mIJulia\u001b[39m \u001b[90m~/.julia/packages/IJulia/e8kqU/src/\u001b[39m\u001b[90m\u001b[4meventloop.jl:8\u001b[24m\u001b[39m\n",
      "   [16] \u001b[0m\u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @ \u001b[39m\u001b[35mIJulia\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:423\u001b[24m\u001b[39m\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mThere was an error during testing\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mThere was an error during testing\u001b[39m",
      "",
      "Stacktrace:",
      " [1] record(ts::Test.FallbackTestSet, t::Union{Test.Error, Test.Fail})",
      "   @ Test /opt/julia-1.7.1/share/julia/stdlib/v1.7/Test/src/Test.jl:903",
      " [2] do_test(result::Test.ExecutionResult, orig_expr::Any)",
      "   @ Test /opt/julia-1.7.1/share/julia/stdlib/v1.7/Test/src/Test.jl:637",
      " [3] top-level scope",
      "   @ /opt/julia-1.7.1/share/julia/stdlib/v1.7/Test/src/Test.jl:445",
      " [4] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "function t_gpu(x, y, pooled)\n",
    "    varx, meanx = var_gpu(x)\n",
    "    vary, meany = var_gpu(y)\n",
    "    nx, ny = size(x, 2), size(y, 2)\n",
    "    T, B = set_thread_block(size(x,1))\n",
    "    \n",
    "    if pooled\n",
    "        @cuda threads=T blocks=B mul_gpu!(varx, nx-1)\n",
    "        @cuda threads=T blocks=B mul_gpu!(vary, ny-1)\n",
    "        @cuda threads=T blocks=B add_arr_gpu!(varx, vary)     # varx = (nx-1)*varx + (ny-1)*vary\n",
    "        @cuda threads=T blocks=B div_gpu!(varx, nx+ny-2)      # varx /= nx+ny-2\n",
    "        #@cuda threads=256 blocks=4 copy_arr_gpu!(vary, varx)\n",
    "        copyto!(vary, varx)\n",
    "    end\n",
    "        \n",
    "    @cuda threads=T blocks=B div_gpu!(varx, nx)\n",
    "    @cuda threads=T blocks=B div_gpu!(vary, ny)\n",
    "    @cuda threads=T blocks=B add_arr_gpu!(varx, vary)  # varx .+= vary\n",
    "    @cuda threads=T blocks=B sqrt_gpu!(varx)\n",
    "    #return varx\n",
    "    @cuda threads=T blocks=B sub_arr_gpu!(meanx, meany)\n",
    "    #return meanx\n",
    "    @cuda threads=T blocks=B div_arr_gpu!(meanx, varx)\n",
    "    return meanx\n",
    "end\n",
    "\n",
    "a = CUDA.rand(Float64, 200, 200)\n",
    "b = CUDA.rand(Float64, 200, 200)\n",
    "pooled = false\n",
    "@test isapprox(\n",
    "    t_gpu(a, b, pooled),\n",
    "    ttest_ind(a, b, pooled)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t Test Statistic: `@cuda` vs. `@.` vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  248.894 μs (428 allocations: 22.92 KiB)\n",
      "  706.026 μs (340 allocations: 19.33 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32768×1 CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}:\n",
       " -0.23448901664480554\n",
       "  0.05901404020274746\n",
       "  0.38193147235097874\n",
       " -1.1025761619685284\n",
       " -0.37842271181044496\n",
       " -0.5640191022990872\n",
       "  0.9204858513562348\n",
       " -0.5540337831883215\n",
       " -2.022682039847497\n",
       " -0.30371442721737457\n",
       "  1.5446552677841405\n",
       " -0.3557875158409345\n",
       " -1.23487851962008\n",
       "  ⋮\n",
       " -0.41275974205144184\n",
       " -1.993862076306121\n",
       " -0.7057823538090785\n",
       " -0.6766744521720237\n",
       "  2.142521777498816\n",
       " -1.7249230335734638\n",
       "  1.0848105576581777\n",
       "  1.2222689568584562\n",
       " -0.5442251380071487\n",
       "  0.11810933367877134\n",
       "  0.5399342464957391\n",
       "  1.2943106132842193"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime t_gpu($x, $y, pooled=$pooled)\n",
    "@btime ttest_ind($x, $y, $pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.525 μs (0 allocations: 0 bytes)\n",
      "  6.128 μs (24 allocations: 1.28 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: all(a .== b)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CUDA.rand(N)\n",
    "b = CUDA.zeros(N)\n",
    "\n",
    "@btime copyto!($b, $a)\n",
    "@btime @cuda threads=T blocks=B copy_arr_gpu!(b, a)\n",
    "@test all(a .== b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing `CuArray`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.660 μs (4 allocations: 128 bytes)\n",
      "  12.167 μs (22 allocations: 1.11 KiB)\n",
      "  26.057 μs (7 allocations: 78.31 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element CuArray{Float64, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime CuArray{Float64, 1}(undef, 10_000)\n",
    "@btime CUDA.zeros(Float64, 10_000)\n",
    "@btime CuArray(zeros(10_000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.7.1",
   "language": "julia",
   "name": "julia-(8-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
