{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.Utils"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDA, Random\n",
    "using Test, BenchmarkTools\n",
    "CUDA.allowscalar(false)\n",
    "\n",
    "#include(\"perm_test.jl\")\n",
    "include(\"utils.jl\")\n",
    "#include(\"kernels/math.jl\")\n",
    "#include(\"kernels/statistics.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(out, target)\n",
       "   Evaluated: isapprox([0.23465727557171628 0.2485496230384655 … 0.4122893253784012 0.2561438289354201; 0.8819117397407821 0.001518806806245213 … 0.24942242498733067 0.1122157156408838; … ; 0.0010706970945601906 0.21002051256851853 … 0.08826481020023773 0.45853883556029945; 0.00938097613007951 0.7228385415041979 … 0.0051217209305691 0.6483206945775573], [0.23465727557171628 0.2485496230384655 … 0.4122893253784012 0.2561438289354201; 0.8819117397407821 0.001518806806245213 … 0.24942242498733067 0.1122157156408838; … ; 0.0010706970945601906 0.21002051256851853 … 0.08826481020023773 0.45853883556029945; 0.00938097613007951 0.7228385415041979 … 0.0051217209305691 0.6483206945775573])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function square!(out)\n",
    "    \"\"\" x .+= val \"\"\"\n",
    "    tidx = (blockIdx().x - 1) * blockDim().x + threadIdx().x  # thread index\n",
    "    stride = blockDim().x * gridDim().x                       # num. threads per block\n",
    "    for i = tidx:stride:length(out)\n",
    "        @inbounds out[i] = out[i]^2\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "out = CUDA.rand(Float64, 100, 100)\n",
    "target = out.^2\n",
    "T, B = Utils.set_thread_block(length(out))\n",
    "@cuda threads=T blocks=B square!(out)\n",
    "@test isapprox(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 0.73% (59.125 MiB/7.936 GiB)\n",
      "No memory pool is in use."
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1 2 … 11 12; 1 2 … 11 13; … ; 8 10 … 19 20; 9 10 … 19 20], [20 19 … 14 13; 20 19 … 14 12; … ; 9 7 … 2 1; 8 7 … 2 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2^15                    # num. samples\n",
    "T, B = set_thread_block(N)\n",
    "nx, ny = 12, 8              # sample sizes for each group\n",
    "x, y = CUDA.rand(Float64, N, nx), CUDA.rand(Float64, N, ny)\n",
    "px, py = partition(nx, ny)\n",
    "px, py = CuArray(px), CuArray(py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Int64}:\n",
       " 1\n",
       " 4\n",
       " 7"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix(reshape(collect(1:9), 3, 3))[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module PermTestCUDA.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(target, out)\n",
       "   Evaluated: isapprox([0.031643789382944466; 0.055284453780260846; … ; 0.08277640566673716; 0.11871314429307622;;], Float32[0.031643815, 0.055284448, 0.091377124, 0.030687094, 0.08767226, 0.08518992, 0.04003726, 0.10078626, 0.0980054, 0.12109852  …  0.07021329, 0.10216088, 0.12837608, 0.13024433, 0.11270077, 0.085193425, 0.078948736, 0.06943999, 0.08277639, 0.11871317])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "include(\"kernels/statistics.jl\")\n",
    "a = CUDA.rand(Float64, 100, 10)\n",
    "target = var(a, dims=2)\n",
    "out = PermTestCUDA.var(a)[1]\n",
    "@test isapprox(target, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "square! (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function square!(out)\n",
    "    \"\"\" x .+= val \"\"\"\n",
    "    tidx = (blockIdx().x - 1) * blockDim().x + threadIdx().x  # thread index\n",
    "    stride = blockDim().x * gridDim().x                       # num. threads per block\n",
    "    for r = tidx:stride:size(out,1)\n",
    "        for c = 1:size(out,2)\n",
    "            @inbounds out[r, c] = out[r, c]^2\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(target, out)\n",
       "   Evaluated: isapprox([0.6830883349302 0.9140290064841784 … 0.17637343025728977 0.0036003048038238433; 0.23035979612363108 0.9108429008292139 … 0.25333633479481776 0.1679700503645073; … ; 0.7853554052148567 0.003943807447645813 … 0.31419032161152644 0.5503153213588036; 0.736625634419431 0.021934806109289547 … 0.6361498940168451 0.4656112816149098], [0.6830883349302 0.9140290064841784 … 0.17637343025728977 0.0036003048038238433; 0.23035979612363108 0.9108429008292139 … 0.25333633479481776 0.1679700503645073; … ; 0.7853554052148567 0.003943807447645813 … 0.31419032161152644 0.5503153213588036; 0.736625634419431 0.021934806109289547 … 0.6361498940168451 0.4656112816149098])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = CUDA.rand(Float64, 100, 10)\n",
    "target = out.^2\n",
    "T, B = Utils.set_thread_block(size(out,1))\n",
    "@cuda threads=T blocks=B square!(out)\n",
    "@test isapprox(target, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_sum! (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function row_sum!(out, x)\n",
    "    \"\"\" x .+= val \"\"\"\n",
    "    tidx = (blockIdx().x - 1) * blockDim().x + threadIdx().x  # thread index\n",
    "    stride = blockDim().x * gridDim().x                       # num. threads per block\n",
    "    for r = tidx:stride:length(out)\n",
    "        for c = 1:size(x,2)\n",
    "            @inbounds out[r] += x[r,c]\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(target, out)\n",
       "   Evaluated: isapprox([4.513177650579503; 4.707070371097462; … ; 4.16275040476062; 5.027291084577776;;], [4.513177650579504, 4.707070371097462, 4.226460164619164, 3.3186319350571756, 3.6231268319745857, 4.887888647001304, 5.507584044270206, 3.8865381301405915, 5.644757372965104, 4.5393377960755235  …  4.065184384067538, 4.8395204141298676, 5.6013532283906935, 3.1759178872690543, 6.369728590588395, 3.8164773268197774, 3.927456633365984, 4.123006611411046, 4.16275040476062, 5.027291084577776])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CUDA.rand(Float64, 100, 10)\n",
    "target = sum(a, dims=2)\n",
    "out = CUDA.zeros(Float64, size(a,1))\n",
    "T, B = Utils.set_thread_block(size(a,1))\n",
    "@cuda threads=T blocks=B row_sum!(out, a)\n",
    "@test isapprox(target, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element CuArray{Float64, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 4.048030390850599\n",
       " 5.200961905942131\n",
       " 5.744431932054138\n",
       " 6.508670961128315\n",
       " 5.325939455564748\n",
       " 4.696683050727755\n",
       " 6.02965665417655\n",
       " 5.032443353611986\n",
       " 6.4608935730751345\n",
       " 5.2153453976357635\n",
       " 6.077999765163987\n",
       " 4.541759223675693\n",
       " 3.4836409128999586\n",
       " ⋮\n",
       " 4.7296249234684895\n",
       " 6.829989160851109\n",
       " 4.504849508609454\n",
       " 4.644734794130288\n",
       " 3.198029939254319\n",
       " 4.2352031453029815\n",
       " 5.6458122959549115\n",
       " 4.741192509799889\n",
       " 4.25002196521156\n",
       " 5.0967300772110375\n",
       " 3.0285168049507147\n",
       " 4.555555410215136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1, block 256\n",
      "thread 2, block 256\n",
      "thread 3, block 256\n",
      "thread 4, block 256\n",
      "thread 5, block 256\n",
      "thread 6, block 256\n",
      "thread 7, block 256\n",
      "thread 8, block 256\n",
      "thread 9, block 256\n",
      "thread 10, block 256\n",
      "thread 11, block 256\n",
      "thread 12, block 256\n",
      "thread 13, block 256\n",
      "thread 14, block 256\n",
      "thread 15, block 256\n",
      "thread 16, block 256\n",
      "thread 17, block 256\n",
      "thread 18, block 256\n",
      "thread 19, block 256\n",
      "thread 20, block 256\n",
      "thread 21, block 256\n",
      "thread 22, block 256\n",
      "thread 23, block 256\n",
      "thread 24, block 256\n",
      "thread 25, block 256\n",
      "thread 26, block 256\n",
      "thread 27, block 256\n",
      "thread 28, block 256\n",
      "thread 29, block 256\n",
      "thread 30, block 256\n",
      "thread 31, block 256\n",
      "thread 32, block 256\n",
      "thread 65, block 256\n",
      "thread 66, block 256\n",
      "thread 67, block 256\n",
      "thread 68, block 256\n",
      "thread 69, block 256\n",
      "thread 70, block 256\n",
      "thread 71, block 256\n",
      "thread 72, block 256\n",
      "thread 73, block 256\n",
      "thread 74, block 256\n",
      "thread 75, block 256\n",
      "thread 76, block 256\n",
      "thread 77, block 256\n",
      "thread 78, block 256\n",
      "thread 79, block 256\n",
      "thread 80, block 256\n",
      "thread 81, block 256\n",
      "thread 82, block 256\n",
      "thread 83, block 256\n",
      "thread 84, block 256\n",
      "thread 85, block 256\n",
      "thread 86, block 256\n",
      "thread 87, block 256\n",
      "thread 88, block 256\n",
      "thread 89, block 256\n",
      "thread 90, block 256\n",
      "thread 91, block 256\n",
      "thread 92, block 256\n",
      "thread 93, block 256\n",
      "thread 94, block 256\n",
      "thread 95, block 256\n",
      "thread 96, block 256\n",
      "thread 33, block 256\n",
      "thread 34, block 256\n",
      "thread 35, block 256\n",
      "thread 36, block 256\n",
      "thread 37, block 256\n",
      "thread 38, block 256\n",
      "thread 39, block 256\n",
      "thread 40, block 256\n",
      "thread 41, block 256\n",
      "thread 42, block 256\n",
      "thread 43, block 256\n",
      "thread 44, block 256\n",
      "thread 45, block 256\n",
      "thread 46, block 256\n",
      "thread 47, block 256\n",
      "thread 48, block 256\n",
      "thread 49, block 256\n",
      "thread 50, block 256\n",
      "thread 51, block 256\n",
      "thread 52, block 256\n",
      "thread 53, block 256\n",
      "thread 54, block 256\n",
      "thread 55, block 256\n",
      "thread 56, block 256\n",
      "thread 57, block 256\n",
      "thread 58, block 256\n",
      "thread 59, block 256\n",
      "thread 60, block 256\n",
      "thread 61, block 256\n",
      "thread 62, block 256\n",
      "thread 63, block 256\n",
      "thread 64, block 256\n",
      "thread 97, block 256\n",
      "thread 98, block 256\n",
      "thread 99, block 256\n",
      "thread 100, block 256\n",
      "thread 101, block 256\n",
      "thread 102, block 256\n",
      "thread 103, block 256\n",
      "thread 104, block 256\n",
      "thread 105, block 256\n",
      "thread 106, block 256\n",
      "thread 107, block 256\n",
      "thread 108, block 256\n",
      "thread 109, block 256\n",
      "thread 110, block 256\n",
      "thread 111, block 256\n",
      "thread 112, block 256\n",
      "thread 113, block 256\n",
      "thread 114, block 256\n",
      "thread 115, block 256\n",
      "thread 116, block 256\n",
      "thread 117, block 256\n",
      "thread 118, block 256\n",
      "thread 119, block 256\n",
      "thread 120, block 256\n",
      "thread 121, block 256\n",
      "thread 122, block 256\n",
      "thread 123, block 256\n",
      "thread 124, block 256\n",
      "thread 125, block 256\n",
      "thread 126, block 256\n",
      "thread 127, block 256\n",
      "thread 128, block 256\n",
      "thread 129, block 256\n",
      "thread 130, block 256\n",
      "thread 131, block 256\n",
      "thread 132, block 256\n",
      "thread 133, block 256\n",
      "thread 134, block 256\n",
      "thread 135, block 256\n",
      "thread 136, block 256\n",
      "thread 137, block 256\n",
      "thread 138, block 256\n",
      "thread 139, block 256\n",
      "thread 140, block 256\n",
      "thread 141, block 256\n",
      "thread 142, block 256\n",
      "thread 143, block 256\n",
      "thread 144, block 256\n",
      "thread 145, block 256\n",
      "thread 146, block 256\n",
      "thread 147, block 256\n",
      "thread 148, block 256\n",
      "thread 149, block 256\n",
      "thread 150, block 256\n",
      "thread 151, block 256\n",
      "thread 152, block 256\n",
      "thread 153, block 256\n",
      "thread 154, block 256\n",
      "thread 155, block 256\n",
      "thread 156, block 256\n",
      "thread 157, block 256\n",
      "thread 158, block 256\n",
      "thread 159, block 256\n",
      "thread 160, block 256\n",
      "thread 193, block 256\n",
      "thread 194, block 256\n",
      "thread 195, block 256\n",
      "thread 196, block 256\n",
      "thread 197, block 256\n",
      "thread 198, block 256\n",
      "thread 199, block 256\n",
      "thread 200, block 256\n",
      "thread 201, block 256\n",
      "thread 202, block 256\n",
      "thread 203, block 256\n",
      "thread 204, block 256\n",
      "thread 205, block 256\n",
      "thread 206, block 256\n",
      "thread 207, block 256\n",
      "thread 208, block 256\n",
      "thread 209, block 256\n",
      "thread 210, block 256\n",
      "thread 211, block 256\n",
      "thread 212, block 256\n",
      "thread 213, block 256\n",
      "thread 214, block 256\n",
      "thread 215, block 256\n",
      "thread 216, block 256\n",
      "thread 217, block 256\n",
      "thread 218, block 256\n",
      "thread 219, block 256\n",
      "thread 220, block 256\n",
      "thread 221, block 256\n",
      "thread 222, block 256\n",
      "thread 223, block 256\n",
      "thread 224, block 256\n",
      "thread 161, block 256\n",
      "thread 162, block 256\n",
      "thread 163, block 256\n",
      "thread 164, block 256\n",
      "thread 165, block 256\n",
      "thread 166, block 256\n",
      "thread 167, block 256\n",
      "thread 168, block 256\n",
      "thread 169, block 256\n",
      "thread 170, block 256\n",
      "thread 171, block 256\n",
      "thread 172, block 256\n",
      "thread 173, block 256\n",
      "thread 174, block 256\n",
      "thread 175, block 256\n",
      "thread 176, block 256\n",
      "thread 177, block 256\n",
      "thread 178, block 256\n",
      "thread 179, block 256\n",
      "thread 180, block 256\n",
      "thread 181, block 256\n",
      "thread 182, block 256\n",
      "thread 183, block 256\n",
      "thread 184, block 256\n",
      "thread 185, block 256\n",
      "thread 186, block 256\n",
      "thread 187, block 256\n",
      "thread 188, block 256\n",
      "thread 189, block 256\n",
      "thread 190, block 256\n",
      "thread 191, block 256\n",
      "thread 192, block 256\n",
      "thread 225, block 256\n",
      "thread 226, block 256\n",
      "thread 227, block 256\n",
      "thread 228, block 256\n",
      "thread 229, block 256\n",
      "thread 230, block 256\n",
      "thread 231, block 256\n",
      "thread 232, block 256\n",
      "thread 233, block 256\n",
      "thread 234, block 256\n",
      "thread 235, block 256\n",
      "thread 236, block 256\n",
      "thread 237, block 256\n",
      "thread 238, block 256\n",
      "thread 239, block 256\n",
      "thread 240, block 256\n",
      "thread 241, block 256\n",
      "thread 242, block 256\n",
      "thread 243, block 256\n",
      "thread 244, block 256\n",
      "thread 245, block 256\n",
      "thread 246, block 256\n",
      "thread 247, block 256\n",
      "thread 248, block 256\n",
      "thread 249, block 256\n",
      "thread 250, block 256\n",
      "thread 251, block 256\n",
      "thread 252, block 256\n",
      "thread 253, block 256\n",
      "thread 254, block 256\n",
      "thread 255, block 256\n",
      "thread 256, block 256\n",
      "modifying array index 1\n",
      "modifying array index 2\n",
      "modifying array index 3\n",
      "modifying array index 4\n",
      "modifying array index 5\n",
      "modifying array index 6\n",
      "modifying array index 7\n",
      "modifying array index 8\n",
      "modifying array index 9\n",
      "modifying array index 10\n"
     ]
    }
   ],
   "source": [
    "a = CUDA.zeros(10)\n",
    "@cuda threads=256 blocks=1 add!(a, 1)\n",
    "a\n",
    "# all(a .== 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t Test Statistic: `@cuda` vs. `@.` vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  248.894 μs (428 allocations: 22.92 KiB)\n",
      "  706.026 μs (340 allocations: 19.33 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32768×1 CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}:\n",
       " -0.23448901664480554\n",
       "  0.05901404020274746\n",
       "  0.38193147235097874\n",
       " -1.1025761619685284\n",
       " -0.37842271181044496\n",
       " -0.5640191022990872\n",
       "  0.9204858513562348\n",
       " -0.5540337831883215\n",
       " -2.022682039847497\n",
       " -0.30371442721737457\n",
       "  1.5446552677841405\n",
       " -0.3557875158409345\n",
       " -1.23487851962008\n",
       "  ⋮\n",
       " -0.41275974205144184\n",
       " -1.993862076306121\n",
       " -0.7057823538090785\n",
       " -0.6766744521720237\n",
       "  2.142521777498816\n",
       " -1.7249230335734638\n",
       "  1.0848105576581777\n",
       "  1.2222689568584562\n",
       " -0.5442251380071487\n",
       "  0.11810933367877134\n",
       "  0.5399342464957391\n",
       "  1.2943106132842193"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime t_gpu($x, $y, pooled=$pooled)\n",
    "@btime ttest_ind($x, $y, $pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.525 μs (0 allocations: 0 bytes)\n",
      "  6.128 μs (24 allocations: 1.28 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: all(a .== b)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CUDA.rand(N)\n",
    "b = CUDA.zeros(N)\n",
    "\n",
    "@btime copyto!($b, $a)\n",
    "@btime @cuda threads=T blocks=B copy_arr_gpu!(b, a)\n",
    "@test all(a .== b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing `CuArray`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.660 μs (4 allocations: 128 bytes)\n",
      "  12.167 μs (22 allocations: 1.11 KiB)\n",
      "  26.057 μs (7 allocations: 78.31 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element CuArray{Float64, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime CuArray{Float64, 1}(undef, 10_000)\n",
    "@btime CUDA.zeros(Float64, 10_000)\n",
    "@btime CuArray(zeros(10_000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.7.1",
   "language": "julia",
   "name": "julia-(8-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
