{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed, Folds, FLoops\n",
    "using Random, Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partition (generic function with 1 method)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"perm_test.jl\")\n",
    "include(\"partition.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256×20 Matrix{Float64}:\n",
       " -0.645731     1.34194    -0.19564   -1.05875    …  -1.35274    -0.370654\n",
       " -1.46325     -1.18862    -0.915458  -0.920206       1.14854    -0.921302\n",
       " -1.6236       1.18954    -0.167391   2.08291        0.297835   -0.483097\n",
       " -0.217665    -1.6712     -0.75522   -0.281233       0.425549    1.91035\n",
       "  0.492246     0.190436   -1.00009    0.0599196     -0.260339   -1.41726\n",
       "  0.98098     -1.27217    -0.498621   0.179808   …   1.58057    -0.460531\n",
       "  0.0799568   -0.803196    0.802551  -0.437841      -0.936614   -0.243236\n",
       "  1.54912      1.97076     0.146786   0.0807004     -1.3201      1.90304\n",
       " -1.34161      1.54823    -0.922078   1.58911       -0.114953    0.109298\n",
       "  0.412162    -0.126723    1.22042    0.668593      -0.399888   -0.910424\n",
       "  0.593197     0.174584   -0.223876   0.749044   …  -0.372004   -0.0788338\n",
       " -0.768409     0.267046   -0.966475  -0.163043      -1.16322    -0.253188\n",
       " -0.0761679    1.326      -0.950514   1.42283        1.16112     0.874681\n",
       "  ⋮                                              ⋱              \n",
       " -0.00399714  -0.798842    0.297035   0.033951       1.08248    -0.729412\n",
       "  0.153829    -2.06012    -1.59517   -0.506355   …   1.58232     1.14605\n",
       " -0.657564    -1.95857    -1.60127    0.455424       1.9772     -1.30463\n",
       "  2.42093      0.0867775  -1.29443    0.947003       0.39451     1.09171\n",
       " -1.05522      0.739542    1.30924   -1.44439       -0.195158    1.17554\n",
       " -0.925165    -0.430667   -0.969424  -1.2785         1.55091     0.363222\n",
       " -0.857617     0.779092    1.30686    1.1397     …   0.952342    1.09501\n",
       " -0.192994     0.857337   -0.498421  -0.888869      -0.598934    0.0109003\n",
       " -0.791916     0.728794   -0.95179    0.220856      -0.0577762  -0.408445\n",
       " -1.21288      0.671962    0.222213   0.24831       -0.802645   -2.15605\n",
       " -1.66074     -0.675715    0.425228   0.941992      -0.126661   -0.327728\n",
       "  0.494462    -0.983256    1.16919   -2.27302    …   0.765671   -1.46501"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, n1, n2 = 256, 12, 8\n",
    "d = Normal()\n",
    "delta_true = 0\n",
    "parts = partition(n1, n2)\n",
    "Random.seed!(123)\n",
    "x1s = rand(d, (n, n1))\n",
    "x2s = rand(d, (n, n2))\n",
    "data = hcat(x1s, x2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[1,:]\n",
    "x1, x2 = x[1:n1], x[n1+1:end]\n",
    "@time permInterval(x1, x2, parts, delta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @distributed (+) for i in 1:n\n",
    "    permInterval(data[i, 1:n1], data[i, n1+1:end], parts, delta_true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @floop for row in eachrow(data)\n",
    "    @reduce(coverage += permInterval(row[1:n1], row[n1+1:end], parts, delta_true))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Folds.reduce(+, Folds.map(x -> permInterval(x[1:n1], x[n1+1:end], parts, delta_true), eachrow(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024×1024 CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.919181   0.292579   0.825846   …  0.168067    0.104088   0.229287\n",
       " 0.426019   0.149323   0.489151      0.235193    0.594976   0.617096\n",
       " 0.746586   0.188196   0.699858      0.960604    0.556726   0.879213\n",
       " 0.819201   0.566957   0.539838      0.990984    0.260809   0.941378\n",
       " 0.954159   0.0496869  0.948309      0.0772474   0.262274   0.561383\n",
       " 0.845895   0.506965   0.0744135  …  0.67193     0.217708   0.41441\n",
       " 0.586749   0.0930013  0.0117718     0.432447    0.79591    0.176363\n",
       " 0.121813   0.997974   0.398319      0.52053     0.80667    0.458327\n",
       " 0.789493   0.709287   0.143511      0.838646    0.840307   0.190893\n",
       " 0.619259   0.910902   0.241169      0.226593    0.0996554  0.564104\n",
       " 0.477645   0.436953   0.220376   …  0.61497     0.89362    0.563459\n",
       " 0.804193   0.673175   0.129352      0.846492    0.479529   0.34562\n",
       " 0.123538   0.6756     0.303669      0.824918    0.986141   0.0999812\n",
       " ⋮                                ⋱                         \n",
       " 0.722624   0.636694   0.459694      0.604943    0.657773   0.610275\n",
       " 0.21389    0.578567   0.483752      0.21971     0.272533   0.298528\n",
       " 0.141777   0.431944   0.460532      0.660918    0.524177   0.736578\n",
       " 0.785873   0.265588   0.837426   …  0.77058     0.65736    0.539105\n",
       " 0.592765   0.237982   0.634604      0.964538    0.0400181  0.743142\n",
       " 0.252843   0.0723859  0.968748      0.346235    0.909828   0.272855\n",
       " 0.141472   0.261119   0.942569      0.00606297  0.84569    0.807491\n",
       " 0.348334   0.0708358  0.372984      0.764866    0.375325   0.904764\n",
       " 0.473375   0.973624   0.382234   …  0.657822    0.253888   0.41692\n",
       " 0.298998   0.278812   0.821165      0.587146    0.637626   0.636816\n",
       " 0.0769627  0.76252    0.971892      0.0477345   0.435208   0.284151\n",
       " 0.486571   0.0158257  0.343417      0.197366    0.843523   0.55869"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDA, Test, Random\n",
    "\n",
    "N = 2^10\n",
    "Random.seed!(123)\n",
    "x1 = CuArray(rand(N, N))\n",
    "x2 = CuArray(rand(N, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student T Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this only covers computing the [T-test stastic](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) and not calculations involving the actual T distribution (e.g., cdf, pdf, quantiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_gpu (generic function with 2 methods)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mean_gpu(x, d)\n",
    "    return sum(x, dims=d) ./= size(x)[d]\n",
    "end\n",
    "\n",
    "function sum_sq_gpu(x, d)\n",
    "    return sum(x.^2, dims=d)\n",
    "end\n",
    "\n",
    "function var_gpu(x, n, mean, ss)\n",
    "    return @. (ss - (n * mean^2)) / (n - 1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: all(mean_gpu(x1, ndims(x1)) .== mean(x1, dims = 2))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test all(mean_gpu(x1, ndims(x1)) .== mean(x1, dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: all(sum_sq_gpu(x1, ndims(x1)) .== sum(x1 .^ 2, dims = 2))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test all(sum_sq_gpu(x1, ndims(x1)) .== sum(x1.^2, dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(var_gpu(x1, n, m, sq), var(x1, dims = 2))\n",
       "   Evaluated: isapprox([0.0833572631339034; 0.08410008546151253; … ; 0.08270401746402671; 0.08124917847073232;;], [0.08335726313390343; 0.0841000854615125; … ; 0.08270401746402672; 0.08124917847073242;;])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = ndims(x1)\n",
    "n = size(x1)[d]\n",
    "m = mean_gpu(x1, ndims(x1))\n",
    "sq = sum_sq_gpu(x1, ndims(x1))\n",
    "@test isapprox(var_gpu(x1, n, m, sq), var(x1, dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t_gpu (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function t_gpu(x1, x2, pooled)\n",
    "    d = ndims(x1)\n",
    "    mean1, mean2 = mean_gpu(x1, d), mean_gpu(x2, d)\n",
    "    ss1, ss2 = sum_sq_gpu(x1, d), sum_sq_gpu(x2, d)\n",
    "    \n",
    "    n1, n2 = size(x1)[d], size(x2)[d]\n",
    "    # TODO implement pooled variance\n",
    "    var1, var2 = var_gpu(x1, n1, mean1, ss1), var_gpu(x2, n2, mean2, ss2)\n",
    "    \n",
    "    return @. (mean1 - mean2) / sqrt(var1/n1 + var2/n2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: isapprox(t_gpu(x1, x2, false), ttest_ind(x1, x2, false))\n",
       "   Evaluated: isapprox([1.206540586996704; -0.9959457166403523; … ; 0.09742026421765294; 0.4959504570725251;;], [1.206540586996704; -0.9959457166403523; … ; 0.09742026421765293; 0.49595045707252494;;])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test isapprox(t_gpu(x1, x2, false), ttest_ind(x1, x2, false))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gpu_sum!(x, y, )\n",
    "    \"\"\"Computes the sum of the 1-D vector x and stores in y[1]\"\"\"\n",
    "    index = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    stride = gridDim().x * blockDim().x\n",
    "    for i = index:stride:length(x)\n",
    "        @inbounds y[1] += x[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numblocks = ceil(Int, N/256)\n",
    "@cuda threads=256 blocks=numblocks gpu_sum!(x, y)\n",
    "#@test all(sum(x) .== y)\n",
    "@test all(x .== y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function bench_gpu3!(y, x)\n",
    "    numblocks = ceil(Int, length(y)/256)\n",
    "    CUDA.@sync begin\n",
    "        @cuda threads=256 blocks=numblocks gpu_add3!(y, x)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "@btime bench_gpu3!($y_d, $x_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.7.1",
   "language": "julia",
   "name": "julia-(8-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
